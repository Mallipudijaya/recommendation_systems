{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the extension of previous simple recommender system where here instead of using lightfm inbuilt dataset we used \n",
    "two datasets on movies \n",
    "on these we did content-based ,collabourative and hybrid recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Filtering\n",
    "In this recommender system the content of the movie (overview, cast, crew, keyword, tagline etc) is used to find its similarity with other movies. Then the movies that are most likely to be similar are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65                              The Dark Knight\n",
       "299                              Batman Forever\n",
       "428                              Batman Returns\n",
       "1359                                     Batman\n",
       "3854    Batman: The Dark Knight Returns, Part 2\n",
       "119                               Batman Begins\n",
       "2507                                  Slow Burn\n",
       "9            Batman v Superman: Dawn of Justice\n",
       "1181                                        JFK\n",
       "210                              Batman & Robin\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#content based filtering\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "df1=pd.read_csv('tmdb_5000_credits.csv')\n",
    "df2=pd.read_csv('tmdb_5000_movies.csv')\n",
    "df1.columns = ['id','tittle','cast','crew']\n",
    "df2= df2.merge(df1,on='id')\n",
    "df2['overview'].head(5)\n",
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "df2['overview'] = df2['overview'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df2['overview'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n",
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df2.index, index=df2['title']).drop_duplicates()\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df2['title'].iloc[movie_indices]\n",
    "get_recommendations('The Dark Knight Rises')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has done a decent job of finding movies with similar plot descriptions, \n",
    "the quality of recommendations is not that great so we improve that using Credits, Genres and Keywords Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits, Genres and Keywords Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we are going to build a recommender based on the following metadata:\n",
    "    the 3 top actors, the director, related genres and the movie plot keywords.so that our recommender accuracy increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65               The Dark Knight\n",
       "119                Batman Begins\n",
       "4638    Amidst the Devil's Wings\n",
       "1196                The Prestige\n",
       "3073           Romeo Is Bleeding\n",
       "3326              Black November\n",
       "1503                      Takers\n",
       "1986                      Faster\n",
       "303                     Catwoman\n",
       "747               Gangster Squad\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the stringified features into their corresponding python objects\n",
    "from ast import literal_eval\n",
    "\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(literal_eval)\n",
    "#Next, we'll write functions that will help us to extract the required information from each feature.\n",
    "\n",
    "# Get the director's name from the crew feature. If director is not listed, return NaN\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "# Returns the list top 3 elements or entire list; whichever is more.\n",
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []\n",
    "# Define new director, cast, genres and keywords features that are in a suitable form.\n",
    "df2['director'] = df2['crew'].apply(get_director)\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(get_list)\n",
    "# Print the new features of the first 3 films\n",
    "df2[['title', 'cast', 'director', 'keywords', 'genres']].head(3)\n",
    "# Function to convert all strings to lower case and strip names of spaces\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''\n",
    "# Apply clean_data function to your features.\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    df2[feature] = df2[feature].apply(clean_data)\n",
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "df2['soup'] = df2.apply(create_soup, axis=1)\n",
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(df2['soup'])\n",
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "# Reset index of our main DataFrame and construct reverse mapping as before\n",
    "df2 = df2.reset_index()\n",
    "indices = pd.Series(df2.index, index=df2['title'])\n",
    "get_recommendations('The Dark Knight Rises', cosine_sim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filters can further be classified into two types:\n",
    "\n",
    "User-based Filtering: these systems recommend products to a user that similar users have liked\n",
    "Item-based Filtering: these systems are extremely similar to the content recommendation engine that you built. \n",
    "These systems identify similar items based on how people have rated it in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COOL\\Anaconda3\\lib\\site-packages\\surprise\\evaluate.py:66: UserWarning: The evaluate() method is deprecated. Please use model_selection.cross_validate() instead.\n",
      "  'model_selection.cross_validate() instead.', UserWarning)\n",
      "C:\\Users\\COOL\\Anaconda3\\lib\\site-packages\\surprise\\dataset.py:193: UserWarning: Using data.split() or using load_from_folds() without using a CV iterator is now deprecated. \n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9006\n",
      "MAE:  0.6904\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.8932\n",
      "MAE:  0.6866\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.8960\n",
      "MAE:  0.6928\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.8941\n",
      "MAE:  0.6894\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.9031\n",
      "MAE:  0.6966\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.8974\n",
      "Mean MAE : 0.6912\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=302, r_ui=3, est=2.756867286395355, details={'was_impossible': False})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collabourative\n",
    "from surprise import Reader, Dataset, SVD, evaluate\n",
    "reader = Reader()\n",
    "ratings = pd.read_csv('ratings_small.csv')\n",
    "ratings.head()\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "data.split(n_folds=5)\n",
    "svd = SVD()\n",
    "evaluate(svd, data, measures=['RMSE', 'MAE'])\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "svd.predict(1, 302, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid Systems can take advantage of \n",
    "content-based and collaborative filtering as the two approaches are proved to be almost complimentary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COOL\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#hybrid one\n",
    "\n",
    "\n",
    "def convert_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "links_small = pd.read_csv('links_small.csv')\n",
    "md = pd.read_csv('movies_metadata.csv')\n",
    "md['genres'] = md['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i[\n",
    "    'name'] for i in x] if isinstance(x, list) else [])\n",
    "md['year'] = pd.to_datetime(md['release_date'], errors='coerce').apply(\n",
    "    lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
    "\n",
    "\n",
    "md['id'] = md['id'].apply(convert_int)\n",
    "md[md['id'].isnull()]\n",
    "md = md.drop([19730, 29503, 35587])\n",
    "md['id'] = md['id'].astype('int')\n",
    "smd = md[md['id'].isin(links_small)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>release_date</th>\n",
       "      <th>id</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>One Crazy Summer</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1986-08-08</td>\n",
       "      <td>18282</td>\n",
       "      <td>3.173402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>High Noon</td>\n",
       "      <td>343.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1952-03-27</td>\n",
       "      <td>288</td>\n",
       "      <td>3.107940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>Enemies: A Love Story</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1989-12-13</td>\n",
       "      <td>116014</td>\n",
       "      <td>2.964289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>Faithful</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1996-04-03</td>\n",
       "      <td>47502</td>\n",
       "      <td>2.849950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>Steel Magnolias</td>\n",
       "      <td>146.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1989-11-15</td>\n",
       "      <td>10860</td>\n",
       "      <td>2.825194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>The War of the Worlds</td>\n",
       "      <td>172.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1953-08-13</td>\n",
       "      <td>8974</td>\n",
       "      <td>2.821450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Heavy</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1995-01-20</td>\n",
       "      <td>22621</td>\n",
       "      <td>2.811527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>Dersu Uzala</td>\n",
       "      <td>90.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1975-08-02</td>\n",
       "      <td>9764</td>\n",
       "      <td>2.797765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>Alien Escape</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1996-01-01</td>\n",
       "      <td>29938</td>\n",
       "      <td>2.776404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>Looking for Richard</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1996-10-11</td>\n",
       "      <td>42314</td>\n",
       "      <td>2.744534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  vote_count  vote_average release_date      id  \\\n",
       "2149       One Crazy Summer        54.0           6.4   1986-08-08   18282   \n",
       "1238              High Noon       343.0           7.6   1952-03-27     288   \n",
       "4461  Enemies: A Love Story        11.0           5.7   1989-12-13  116014   \n",
       "654                Faithful         4.0           4.8   1996-04-03   47502   \n",
       "3720        Steel Magnolias       146.0           7.1   1989-11-15   10860   \n",
       "2547  The War of the Worlds       172.0           6.8   1953-08-13    8974   \n",
       "746                   Heavy        11.0           7.7   1995-01-20   22621   \n",
       "3350            Dersu Uzala        90.0           8.0   1975-08-02    9764   \n",
       "1613           Alien Escape         2.0           4.5   1996-01-01   29938   \n",
       "1020    Looking for Richard        33.0           6.9   1996-10-11   42314   \n",
       "\n",
       "           est  \n",
       "2149  3.173402  \n",
       "1238  3.107940  \n",
       "4461  2.964289  \n",
       "654   2.849950  \n",
       "3720  2.825194  \n",
       "2547  2.821450  \n",
       "746   2.811527  \n",
       "3350  2.797765  \n",
       "1613  2.776404  \n",
       "1020  2.744534  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def convert_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "links_small = pd.read_csv('links_small.csv')\n",
    "id_map = pd.read_csv('links_small.csv')[['movieId', 'tmdbId']]\n",
    "id_map['tmdbId'] = id_map['tmdbId'].apply(convert_int)\n",
    "id_map.columns = ['movieId', 'id']\n",
    "id_map = id_map.merge(smd[['title', 'id']], on='id').set_index('title')\n",
    "indices_map = id_map.set_index('id')\n",
    "def hybrid(userId, title):\n",
    "    idx = indices[title]\n",
    "    tmdbId = id_map.loc[title]['id']\n",
    "    movie_id = id_map.loc[title]['movieId']\n",
    "    sim_scores = list(enumerate(cosine_sim[int(idx)]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:26]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    movies = smd.iloc[movie_indices][['title', 'vote_count', 'vote_average', 'release_date', 'id']]\n",
    "    movies['est'] = movies['id'].apply(lambda x: svd.predict(userId, indices_map.loc[x]['movieId']).est)\n",
    "    movies = movies.sort_values('est', ascending=False)\n",
    "    return movies.head(10)\n",
    "hybrid(1, 'Avatar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
